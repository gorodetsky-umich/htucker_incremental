{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ddb32a9",
   "metadata": {},
   "source": [
    "# HTucker: Hierarchical Tucker Tensor Decomposition\n",
    "\n",
    "This notebook demonstrates how to use the HTucker package for tensor decomposition and compression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1623c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import htucker as ht\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e839e270",
   "metadata": {},
   "source": [
    "## 1. Creating a Test Tensor\n",
    "\n",
    "Let's start by creating a synthetic tensor with some structure to demonstrate compression capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0781bf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensor with low-rank structure plus noise\n",
    "def create_test_tensor(shape=(10, 8, 6, 4), rank=2, noise_level=0.05):\n",
    "    \"\"\"Create a tensor with specified shape, approximate rank, and noise level.\n",
    "    \n",
    "    Args:\n",
    "        shape: Shape of the tensor\n",
    "        rank: Approximate rank for each mode\n",
    "        noise_level: Level of noise to add\n",
    "        \n",
    "    Returns:\n",
    "        ndarray: The created tensor\n",
    "    \"\"\"\n",
    "    # Create factors for each dimension\n",
    "    factors = []\n",
    "    for dim_size in shape:\n",
    "        # Create random factors\n",
    "        factor = np.random.rand(dim_size, rank)\n",
    "        factors.append(factor)\n",
    "    \n",
    "    # Create core tensor\n",
    "    core = np.random.rand(*([rank] * len(shape)))\n",
    "    \n",
    "    # Initialize tensor\n",
    "    tensor = np.zeros(shape)\n",
    "    \n",
    "    # Build tensor from factors - this creates a low-rank structure\n",
    "    # This is a simple implementation and not the most efficient way\n",
    "    # For high-dimensional tensors, one would use proper tensor operations\n",
    "    index_ranges = [range(s) for s in shape]\n",
    "    for idx in np.ndindex(*shape):\n",
    "        value = 0\n",
    "        for r_idx in np.ndindex(*([rank] * len(shape))):\n",
    "            tmp = core[r_idx]\n",
    "            for i, (dim_idx, r) in enumerate(zip(idx, r_idx)):\n",
    "                tmp *= factors[i][dim_idx, r]\n",
    "            value += tmp\n",
    "        tensor[idx] = value\n",
    "    \n",
    "    # Add noise\n",
    "    if noise_level > 0:\n",
    "        noise = np.random.normal(0, noise_level * np.std(tensor), size=shape)\n",
    "        tensor += noise\n",
    "    \n",
    "    return tensor\n",
    "\n",
    "# Create tensor\n",
    "np.random.seed(42)  # For reproducibility\n",
    "tensor_shape = (10, 8, 6, 4)\n",
    "tensor = create_test_tensor(shape=tensor_shape, rank=3, noise_level=0.1)\n",
    "\n",
    "# Print information\n",
    "print(f\"Tensor shape: {tensor.shape}\")\n",
    "print(f\"Tensor size: {tensor.size} elements\")\n",
    "print(f\"Memory usage: {tensor.nbytes / 1024:.2f} KB\")\n",
    "\n",
    "# Show a slice of the tensor\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(tensor[0, :, :, 0], cmap='viridis')\n",
    "plt.title('Tensor Slice [0, :, :, 0]')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(tensor[:, :, 0, 0], cmap='viridis')\n",
    "plt.title('Tensor Slice [:, :, 0, 0]')\n",
    "plt.colorbar()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c49c08d",
   "metadata": {},
   "source": [
    "## 2. Creating a Dimension Tree\n",
    "\n",
    "The HTucker decomposition requires a dimension tree that defines how the tensor dimensions are hierarchically organized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36d2453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dimension tree\n",
    "dim_tree = ht.createDimensionTree(tensor, 2, 1)\n",
    "\n",
    "# Print dimension tree information\n",
    "print(f\"Dimension tree created with {dim_tree._leafCount} leaves\")\n",
    "print(\"\\nDimension tree structure:\")\n",
    "for node in dim_tree.nodes:\n",
    "    if node.parent is not None:\n",
    "        parent_dims = node.parent.dimensions\n",
    "    else:\n",
    "        parent_dims = \"None (root)\"\n",
    "    print(f\"Node dimensions: {node.dimensions}, Parent: {parent_dims}\")\n",
    "\n",
    "# Visualize the dimension tree structure (simple text representation)\n",
    "def print_tree(node, level=0):\n",
    "    indent = \"  \" * level\n",
    "    print(f\"{indent}Node: {node.dimensions}\")\n",
    "    for child in node.children:\n",
    "        print_tree(child, level + 1)\n",
    "\n",
    "print(\"\\nTree structure:\")\n",
    "print_tree(dim_tree.root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8220c5b2",
   "metadata": {},
   "source": [
    "## 3. Root-to-Leaf Compression\n",
    "\n",
    "Now let's compress the tensor using the HTucker root-to-leaf approach, which applies HOSVD starting from the root node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312f2491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize HTucker object\n",
    "htd_r2l = ht.HTucker()\n",
    "htd_r2l.initialize(tensor)\n",
    "\n",
    "# Compress using root-to-leaf approach\n",
    "start_time = time.time()\n",
    "htd_r2l.compress_root2leaf(tensor)\n",
    "r2l_time = time.time() - start_time\n",
    "print(f\"Root-to-leaf compression time: {r2l_time:.4f} seconds\")\n",
    "\n",
    "# Check if compression succeeded\n",
    "print(f\"Compression completed: {htd_r2l._iscompressed}\")\n",
    "\n",
    "# Reconstruct the tensor\n",
    "start_time = time.time()\n",
    "reconstructed_r2l = htd_r2l.reconstruct_all()\n",
    "reconstruct_time = time.time() - start_time\n",
    "print(f\"Reconstruction time: {reconstruct_time:.4f} seconds\")\n",
    "\n",
    "# Calculate error\n",
    "rel_error_r2l = np.linalg.norm(reconstructed_r2l - tensor) / np.linalg.norm(tensor)\n",
    "print(f\"Relative reconstruction error: {rel_error_r2l:.8e}\")\n",
    "\n",
    "# Memory usage\n",
    "memory_r2l = htd_r2l.get_memory_size()\n",
    "compression_ratio_r2l = tensor.nbytes / memory_r2l\n",
    "print(f\"Memory usage: {memory_r2l / 1024:.2f} KB\")\n",
    "print(f\"Compression ratio: {compression_ratio_r2l:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292d044a",
   "metadata": {},
   "source": [
    "## 4. Leaf-to-Root Compression\n",
    "\n",
    "Now let's try the leaf-to-root compression approach, which applies truncated SVD starting from the leaf nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fad9bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize HTucker object\n",
    "htd_l2r = ht.HTucker()\n",
    "htd_l2r.initialize(tensor, dimension_tree=dim_tree)\n",
    "\n",
    "# Set relative tolerance for SVD truncation\n",
    "htd_l2r.rtol = 1e-6\n",
    "print(f\"Using relative tolerance: {htd_l2r.rtol}\")\n",
    "\n",
    "# Compress using leaf-to-root approach\n",
    "start_time = time.time()\n",
    "htd_l2r.compress_leaf2root(tensor, dim_tree)\n",
    "l2r_time = time.time() - start_time\n",
    "print(f\"Leaf-to-root compression time: {l2r_time:.4f} seconds\")\n",
    "\n",
    "# Reconstruct the tensor\n",
    "start_time = time.time()\n",
    "reconstructed_l2r = htd_l2r.reconstruct_all()\n",
    "reconstruct_time_l2r = time.time() - start_time\n",
    "print(f\"Reconstruction time: {reconstruct_time_l2r:.4f} seconds\")\n",
    "\n",
    "# Calculate error\n",
    "rel_error_l2r = np.linalg.norm(reconstructed_l2r - tensor) / np.linalg.norm(tensor)\n",
    "print(f\"Relative reconstruction error: {rel_error_l2r:.8e}\")\n",
    "\n",
    "# Memory usage\n",
    "memory_l2r = htd_l2r.get_memory_size()\n",
    "compression_ratio_l2r = tensor.nbytes / memory_l2r\n",
    "print(f\"Memory usage: {memory_l2r / 1024:.2f} KB\")\n",
    "print(f\"Compression ratio: {compression_ratio_l2r:.2f}x\")\n",
    "\n",
    "# Show ranks\n",
    "print(f\"\\nRanks after compression: {htd_l2r.get_ranks()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89958461",
   "metadata": {},
   "source": [
    "## 5. Comparison of Compression Methods\n",
    "\n",
    "Let's compare the results of the two compression methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b69c18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison table\n",
    "comparison = {\n",
    "    'Method': ['Root-to-Leaf', 'Leaf-to-Root'],\n",
    "    'Compression Time (s)': [r2l_time, l2r_time],\n",
    "    'Reconstruction Time (s)': [reconstruct_time, reconstruct_time_l2r],\n",
    "    'Relative Error': [rel_error_r2l, rel_error_l2r],\n",
    "    'Memory (KB)': [memory_r2l / 1024, memory_l2r / 1024],\n",
    "    'Compression Ratio': [compression_ratio_r2l, compression_ratio_l2r]\n",
    "}\n",
    "\n",
    "# Print comparison\n",
    "from tabulate import tabulate\n",
    "try:\n",
    "    from tabulate import tabulate\n",
    "    headers = comparison.keys()\n",
    "    rows = list(zip(*comparison.values()))\n",
    "    print(tabulate(rows, headers=headers, floatfmt='.4f'))\n",
    "except ImportError:\n",
    "    print(\"Install tabulate for better formatting: pip install tabulate\")\n",
    "    for key, values in comparison.items():\n",
    "        print(f\"{key}:\")\n",
    "        for method, value in zip(comparison['Method'], values):\n",
    "            print(f\"  {method}: {value}\")\n",
    "\n",
    "# Visualization of original vs reconstructed\n",
    "slice_idx = (0, slice(None), slice(None), 0)\n",
    "\n",
    "plt.figure(figsize=(15, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(tensor[slice_idx], cmap='viridis')\n",
    "plt.title('Original Tensor')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(reconstructed_r2l[slice_idx], cmap='viridis')\n",
    "plt.title('Root-to-Leaf Reconstruction')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(reconstructed_l2r[slice_idx], cmap='viridis')\n",
    "plt.title('Leaf-to-Root Reconstruction')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3699eb12",
   "metadata": {},
   "source": [
    "## 6. Effect of Tolerance Parameter\n",
    "\n",
    "Let's explore how the tolerance parameter affects compression ratio and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1791f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different tolerance values\n",
    "tolerances = [1e-10, 1e-8, 1e-6, 1e-4, 1e-2, 1e-1]\n",
    "results = []\n",
    "\n",
    "for tol in tolerances:\n",
    "    # Initialize HTucker object\n",
    "    htd_test = ht.HTucker()\n",
    "    htd_test.initialize(tensor, dimension_tree=dim_tree)\n",
    "    htd_test.rtol = tol\n",
    "    \n",
    "    # Compress\n",
    "    htd_test.compress_leaf2root(tensor, dim_tree)\n",
    "    \n",
    "    # Reconstruct\n",
    "    reconstructed = htd_test.reconstruct_all()\n",
    "    \n",
    "    # Calculate error and memory\n",
    "    rel_error = np.linalg.norm(reconstructed - tensor) / np.linalg.norm(tensor)\n",
    "    memory = htd_test.get_memory_size()\n",
    "    compression_ratio = tensor.nbytes / memory\n",
    "    \n",
    "    results.append({\n",
    "        'tolerance': tol,\n",
    "        'rel_error': rel_error,\n",
    "        'compression_ratio': compression_ratio,\n",
    "        'memory_kb': memory / 1024,\n",
    "        'ranks': htd_test.get_ranks()\n",
    "    })\n",
    "    \n",
    "    print(f\"Tolerance: {tol:.1e}, Error: {rel_error:.8e}, Compression: {compression_ratio:.2f}x\")\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.loglog([r['tolerance'] for r in results], [r['rel_error'] for r in results], 'o-')\n",
    "plt.xlabel('Tolerance')\n",
    "plt.ylabel('Relative Error')\n",
    "plt.title('Error vs Tolerance')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.semilogx([r['tolerance'] for r in results], [r['compression_ratio'] for r in results], 'o-')\n",
    "plt.xlabel('Tolerance')\n",
    "plt.ylabel('Compression Ratio')\n",
    "plt.title('Compression Ratio vs Tolerance')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9430e748",
   "metadata": {},
   "source": [
    "## 7. Incremental Update\n",
    "\n",
    "One of the key features of HTucker is the ability to incrementally update the decomposition with new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3933164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new tensor with slightly different structure\n",
    "new_tensor = create_test_tensor(shape=tensor_shape, rank=3, noise_level=0.15)\n",
    "\n",
    "# Use our existing decomposition and update it\n",
    "print(\"Original ranks before update:\", htd_l2r.get_ranks())\n",
    "\n",
    "# Perform incremental update\n",
    "start_time = time.time()\n",
    "htd_l2r.incremental_update(new_tensor)\n",
    "update_time = time.time() - start_time\n",
    "print(f\"Incremental update time: {update_time:.4f} seconds\")\n",
    "print(\"Ranks after update:\", htd_l2r.get_ranks())\n",
    "\n",
    "# Project and reconstruct the new tensor\n",
    "projected = htd_l2r.project(new_tensor)\n",
    "reconstructed_new = htd_l2r.reconstruct(projected)\n",
    "\n",
    "# Calculate error\n",
    "rel_error_new = np.linalg.norm(reconstructed_new - new_tensor) / np.linalg.norm(new_tensor)\n",
    "print(f\"Relative reconstruction error for new tensor: {rel_error_new:.8e}\")\n",
    "\n",
    "# Compare with a fresh decomposition\n",
    "htd_fresh = ht.HTucker()\n",
    "htd_fresh.initialize(new_tensor, dimension_tree=dim_tree)\n",
    "htd_fresh.rtol = 1e-6\n",
    "\n",
    "start_time = time.time()\n",
    "htd_fresh.compress_leaf2root(new_tensor, dim_tree)\n",
    "fresh_time = time.time() - start_time\n",
    "print(f\"Fresh compression time: {fresh_time:.4f} seconds\")\n",
    "print(f\"Speed-up from incremental update: {fresh_time/update_time:.2f}x\")\n",
    "\n",
    "reconstructed_fresh = htd_fresh.reconstruct_all()\n",
    "rel_error_fresh = np.linalg.norm(reconstructed_fresh - new_tensor) / np.linalg.norm(new_tensor)\n",
    "print(f\"Relative reconstruction error for fresh decomposition: {rel_error_fresh:.8e}\")\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(15, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(new_tensor[slice_idx], cmap='viridis')\n",
    "plt.title('New Tensor')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(reconstructed_new[slice_idx], cmap='viridis')\n",
    "plt.title(f'Incremental Update\\nError: {rel_error_new:.2e}')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(reconstructed_fresh[slice_idx], cmap='viridis')\n",
    "plt.title(f'Fresh Decomposition\\nError: {rel_error_fresh:.2e}')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b231488d",
   "metadata": {},
   "source": [
    "## 8. Batch Processing\n",
    "\n",
    "HTucker can efficiently handle batch data by treating one dimension as a batch dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecc74ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a batch tensor\n",
    "batch_size = 5\n",
    "batch_tensor = np.zeros((*tensor_shape[:-1], batch_size))\n",
    "\n",
    "# Fill with different test tensors\n",
    "for b in range(batch_size):\n",
    "    # Create tensor with varying parameters\n",
    "    noise_level = 0.05 + 0.05 * b  # Increasing noise level\n",
    "    batch_tensor[..., b] = create_test_tensor(\n",
    "        shape=tensor_shape[:-1], \n",
    "        rank=3, \n",
    "        noise_level=noise_level\n",
    "    )\n",
    "\n",
    "print(f\"Batch tensor shape: {batch_tensor.shape}\")\n",
    "\n",
    "# Create dimension tree (excluding batch dimension)\n",
    "batch_tree = ht.createDimensionTree(batch_tensor.shape[:-1], 2, 1)\n",
    "\n",
    "# Initialize HTucker for batch processing\n",
    "batch_dimension = len(batch_tensor.shape) - 1  # Last dimension is batch\n",
    "htd_batch = ht.HTucker()\n",
    "htd_batch.initialize(batch_tensor, dimension_tree=batch_tree, \n",
    "                      batch=True, batch_dimension=batch_dimension)\n",
    "htd_batch.rtol = 1e-6\n",
    "\n",
    "# Compress batch tensor\n",
    "start_time = time.time()\n",
    "htd_batch.compress_leaf2root_batch(batch_tensor, batch_tree, batch_dimension=batch_dimension)\n",
    "batch_time = time.time() - start_time\n",
    "print(f\"Batch compression time: {batch_time:.4f} seconds\")\n",
    "\n",
    "# Check if batch count matches\n",
    "print(f\"Batch count in HTucker: {htd_batch.batch_count}\")\n",
    "print(f\"Expected batch count: {batch_size}\")\n",
    "\n",
    "# Reconstruct individual batch samples\n",
    "batch_errors = []\n",
    "reconstructions = []\n",
    "\n",
    "for b in range(batch_size):\n",
    "    # Extract sample\n",
    "    sample = batch_tensor[..., b:b+1]\n",
    "    \n",
    "    # Project\n",
    "    projected = htd_batch.project(sample, batch=True, batch_dimension=batch_dimension)\n",
    "    \n",
    "    # Reconstruct\n",
    "    reconstructed = htd_batch.reconstruct(projected, batch=True, batch_dimension=batch_dimension)\n",
    "    reconstructed = reconstructed[..., 0]  # Remove singleton batch dimension\n",
    "    \n",
    "    # Calculate error\n",
    "    original = sample[..., 0]  # Remove singleton batch dimension\n",
    "    error = np.linalg.norm(reconstructed - original) / np.linalg.norm(original)\n",
    "    batch_errors.append(error)\n",
    "    reconstructions.append(reconstructed)\n",
    "    \n",
    "    print(f\"Batch {b} - Relative error: {error:.8e}\")\n",
    "\n",
    "# Plot batch results\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for b in range(batch_size):\n",
    "    # Original\n",
    "    plt.subplot(batch_size, 3, 3*b + 1)\n",
    "    plt.imshow(batch_tensor[0, :, :, b], cmap='viridis')\n",
    "    if b == 0:\n",
    "        plt.title('Original')\n",
    "    plt.ylabel(f\"Batch {b}\")\n",
    "    plt.colorbar()\n",
    "    \n",
    "    # Reconstructed\n",
    "    plt.subplot(batch_size, 3, 3*b + 2)\n",
    "    plt.imshow(reconstructions[b][0, :, :], cmap='viridis')\n",
    "    if b == 0:\n",
    "        plt.title('Reconstructed')\n",
    "    plt.colorbar()\n",
    "    \n",
    "    # Error\n",
    "    plt.subplot(batch_size, 3, 3*b + 3)\n",
    "    diff = batch_tensor[0, :, :, b] - reconstructions[b][0, :, :]\n",
    "    plt.imshow(diff, cmap='RdBu_r')\n",
    "    if b == 0:\n",
    "        plt.title('Difference')\n",
    "    plt.colorbar()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e64234",
   "metadata": {},
   "source": [
    "## 9. Conclusion\n",
    "\n",
    "In this notebook, we've demonstrated the key features of the HTucker package:\n",
    "\n",
    "1. Root-to-leaf compression\n",
    "2. Leaf-to-root compression with error control\n",
    "3. Incremental updates for efficient processing of new data\n",
    "4. Batch processing for handling multiple tensors simultaneously\n",
    "\n",
    "HTucker is particularly useful for high-dimensional tensors where traditional tensor decomposition methods become computationally infeasible. By exploiting the hierarchical structure, HTucker achieves efficient compression and reconstruction while maintaining accuracy."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
